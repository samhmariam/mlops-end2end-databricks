{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "461dd7b8-52ca-40e8-bb40-9ce4fd802b0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Managing the model lifecycle in Unity Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77841927-871e-4491-ab83-b77f809da918",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 01. Programmatically find best run and push model to Unity Catalog for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87db5e36-a32d-42c4-bd80-b8cd1fc87731",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Paramets \n",
    "catalog = \"workspace\"\n",
    "db = \"customer_churn\"\n",
    "xp_name = \"mlops_customer_churn_experiment\"\n",
    "xp_path = f\"/Users/samuel.hmariam@shewit.co.uk\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30f450be-e02a-40df-b849-f7e2008a8e75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "model_name = f\"{catalog}.{db}.advanced_mlops_churn\"\n",
    "\n",
    "print(f\"Finding best run from {xp_name} and pushing new model version to {model_name}\")\n",
    "mlflow.set_experiment(f\"{xp_path}/{xp_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f08be3a2-289a-4d10-aeda-6e67689495a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's get our best ml run\n",
    "best_model = mlflow.search_runs(\n",
    "  order_by=[\"metrics.test_f1_score DESC\"],\n",
    "  max_results=1,\n",
    "  filter_string=\"status = 'FINISHED' and run_name='mlops_best_run'\" #filter on mlops_best_run to always use the notebook 02 to have a more predictable demo\n",
    ")\n",
    "# Optional: Load MLflow Experiment as a spark df and see all runs\n",
    "# df = spark.read.format(\"mlflow-experiment\").load(experiment_id)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed9b7779-d4a4-4c72-9d8d-a66f2f63febb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Registering model to {catalog}.{db}.advanced_mlops_churn\")\n",
    "\n",
    "# Get the run id from the best model\n",
    "run_id = best_model.iloc[0]['run_id']\n",
    "\n",
    "# Register best model from experiments run to MLflow model registry\n",
    "model_details = mlflow.register_model(f\"runs:/{run_id}/model\", f\"{catalog}.{db}.advanced_mlops_churn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb0b4fdc-ef6c-4945-8668-6d339dd0d5ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 02. Give the registered model a description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "375c141a-a304-4f10-8090-81f7286307e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# The main model description, typically done once.\n",
    "client.update_registered_model(\n",
    "  name=model_details.name,\n",
    "  description=\"This model predicts whether a customer will churn using the features in the advanced_churn_feature_table table. It is used to power the Telco Churn Dashboard in DB SQL.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fc7895a-5879-4c49-bf70-714c4a76d52f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Provide more details on this specific model version\n",
    "best_score = best_model['metrics.test_f1_score'].values[0]\n",
    "run_name = best_model['tags.mlflow.runName'].values[0]\n",
    "version_desc = f\"This model version has an F1 validation metric of {round(best_score,4)*100}%. Follow the link to its training run for more details.\"\n",
    "\n",
    "client.update_model_version(\n",
    "  name=model_details.name,\n",
    "  version=model_details.version,\n",
    "  description=version_desc\n",
    ")\n",
    "\n",
    "# We can also tag the model version with the F1 score for visibility\n",
    "client.set_model_version_tag(\n",
    "  name=model_details.name,\n",
    "  version=model_details.version,\n",
    "  key=\"f1_score\",\n",
    "  value=f\"{round(best_score,4)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c47653e3-7729-4973-a302-e21075e013af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Set the latest model version as the Challenger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c66dc336-440f-472b-a820-2e087c96165f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set this version as the Challenger model, using its model alias\n",
    "client.set_registered_model_alias(\n",
    "  name=f\"{catalog}.{db}.advanced_mlops_churn\",\n",
    "  alias=\"Challenger\",\n",
    "  version=model_details.version\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01-managing-model-in-uc",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c8b9dd5-0869-4207-8e05-e47234dc0c78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Churn Prediction Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17b4128b-529b-4a26-b4d7-d1cb4d2735ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 01. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3f76dd5-2ab2-41dc-8196-315e31eb3932",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read into Spark Dataframe\n",
    "telcoDF = spark.read.table(\"workspace.customer_churn.churn_bronze_customers\")\n",
    "display(telcoDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4715e194-35d1-400a-92d2-7c2f91d59f16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 02. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "999ea6d4-6151-4335-ba75-05f4e7a60d57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Compute the number of active services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cb21c9e-050c-404c-b2f0-c9b39fa6c914",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame as SparkDataFrame\n",
    "from pyspark.sql.functions import pandas_udf, col, when, lit\n",
    "\n",
    "\n",
    "#  Count the number of optional services enabled, like streaming TV\n",
    "def compute_service_features(inputDF: SparkDataFrame) -> SparkDataFrame:\n",
    "  # Create pandas UDF function\n",
    "  @pandas_udf('double')\n",
    "  def num_optional_services(*cols):\n",
    "    # Nested helper function to count the number of optional services in a pandas dataframe\n",
    "    return sum(map(lambda s: (s == \"Yes\").astype('double'), cols))\n",
    "\n",
    "  return inputDF.\\\n",
    "    withColumn(\"num_optional_services\",\n",
    "        num_optional_services(\"online_security\", \"online_backup\", \"device_protection\", \"tech_support\", \"streaming_tv\", \"streaming_movies\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6d098c5-2e54-4d33-9fa8-5db1169ae459",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Define featurization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b05f77a3-0e84-4e34-9cd9-e6ed821db751",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_churn_features(dataDF: SparkDataFrame) -> SparkDataFrame:\n",
    "  \"\"\"\n",
    "  Simple cleaning function leveraging the Pandas API\n",
    "  \"\"\"\n",
    "\n",
    "  # Convert to pandas on spark dataframe\n",
    "  data_psdf = dataDF.pandas_api()\n",
    "\n",
    "  # Convert some columns\n",
    "  data_psdf = data_psdf.astype({\"senior_citizen\": \"string\"})\n",
    "  data_psdf[\"senior_citizen\"] = data_psdf[\"senior_citizen\"].map({\"1\" : \"Yes\", \"0\" : \"No\"})\n",
    "\n",
    "  data_psdf[\"total_charges\"] = data_psdf[\"total_charges\"].apply(lambda x: float(x) if x.strip() else 0)\n",
    "\n",
    "  # Fill some missing numerical values with 0\n",
    "  data_psdf = data_psdf.fillna({\"tenure\": 0.0})\n",
    "  data_psdf = data_psdf.fillna({\"monthly_charges\": 0.0})\n",
    "  data_psdf = data_psdf.fillna({\"total_charges\": 0.0})\n",
    "\n",
    "  # Add/Force semantic data types for specific columns (to facilitate autoML)\n",
    "  data_cleanDF = data_psdf.to_spark()\n",
    "  data_cleanDF = data_cleanDF.withMetadata(\"customer_id\", {\"spark.contentAnnotation.semanticType\":\"native\"})\n",
    "  data_cleanDF = data_cleanDF.withMetadata(\"num_optional_services\", {\"spark.contentAnnotation.semanticType\":\"numeric\"})\n",
    "\n",
    "  return data_cleanDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf956ec3-8a0c-4465-a726-b8af74f34cdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Compute Churn Features and append a timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd3b7c2c-5150-4a11-a03f-b36772186d9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "\n",
    "# Add current scoring timestamp\n",
    "this_time = (datetime.now()).timestamp()\n",
    "churn_features_n_predsDF = clean_churn_features(compute_service_features(telcoDF)) \\\n",
    "                            .withColumn(\"transaction_ts\", lit(this_time).cast(\"timestamp\"))\n",
    "\n",
    "display(churn_features_n_predsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b388f9c-76f1-47fe-9817-ce3f8aea7954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Extract ground-truth labels in a separate table and drop them from the feature table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e06c6ea3-2ac4-4145-acb1-00f490e451f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "# Best practice: specify train-val-test split as categorical label (to be used by automl and/or model validation jobs)\n",
    "train_ratio, val_ratio, test_ratio = 0.7, 0.2, 0.1\n",
    "\n",
    "churn_features_n_predsDF.select(\"customer_id\", \"transaction_ts\", \"churn\") \\\n",
    "                        .withColumn(\"random\", F.rand(seed=42)) \\\n",
    "                        .withColumn(\"split\",\n",
    "                                    F.when(F.col(\"random\") < train_ratio, \"train\")\n",
    "                                    .when(F.col(\"random\") < train_ratio + val_ratio, \"validate\")\n",
    "                                    .otherwise(\"test\")) \\\n",
    "                        .drop(\"random\") \\\n",
    "                        .write.format(\"delta\") \\\n",
    "                        .mode(\"overwrite\").option(\"overwriteSchema\", \"true\") \\\n",
    "                        .saveAsTable(f\"workspace.customer_churn.advanced_churn_label_table\")\n",
    "\n",
    "churn_featuresDF = churn_features_n_predsDF.drop(\"churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3037a59-6cbc-4cc7-8e32-2cc742a0c16f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(churn_featuresDF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7aef2839-ada2-4305-895e-f090a37c9c71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Add primary key constraints to the label table for feature lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76fb48f9-9eb3-4ee4-a2f0-04fd1a1b9b56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set the catalog and schema\n",
    "\n",
    "catalog = \"workspace\"\n",
    "schema = \"customer_churn\"\n",
    "\n",
    "spark.sql(f\"USE {catalog}.{schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e98a890-a58e-4eb0-8b6a-160f0b8af1d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "ALTER TABLE advanced_churn_label_table DROP CONSTRAINT IF EXISTS advanced_churn_label_table_pk;\n",
    "ALTER TABLE advanced_churn_label_table ALTER COLUMN customer_id SET NOT NULL;\n",
    "ALTER TABLE advanced_churn_label_table ALTER COLUMN transaction_ts SET NOT NULL;\n",
    "ALTER TABLE advanced_churn_label_table ADD CONSTRAINT advanced_churn_label_table_pk PRIMARY KEY(customer_id, transaction_ts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82de252d-6d7b-4441-8967-ae9e56088353",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 03. Write the feature table to Unity Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05fcb81b-3734-493d-9791-4c2e092e1a59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Drop any existing online table (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "030a5a73-c101-4772-aabb-207a471b4edf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set the catalog and schema\n",
    "\n",
    "catalog = \"workspace\"\n",
    "db = \"customer_churn\"\n",
    "\n",
    "spark.sql(f\"USE {catalog}.{db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "751c43e4-fb33-47e0-a357-78061b4761b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "\n",
    "# Create a workspace client instance\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# Remove any existing online feature table\n",
    "try:\n",
    "  online_table_specs = w.online_tables.get(f\"{catalog}.{db}.advanced_churn_feature_table_online_table\")\n",
    "  # Drop existing online feature table\n",
    "  w.online_tables.delete(f\"{catalog}.{db}.advanced_churn_feature_table_online_table\")\n",
    "  print(f\"Dropping online feature table: {catalog}.{db}.advanced_churn_feature_table_online_table\")\n",
    "\n",
    "except Exception as e:\n",
    "  pprint(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8bdccdd-f40b-4fa8-a666-a8a7dde18eff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Drop the feature table if it already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6af1d326-09e5-41ee-b040-5902ca85fe59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- We are creating the feature table from scratch.\n",
    "-- Let's drop any existing feature table if it exists\n",
    "DROP TABLE IF EXISTS advanced_churn_feature_table;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "780e67ed-75fa-4891-9675-4ed846595423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Import Feature Store Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b488c3a-1971-4ded-92c3-eed1af1b8464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "fe = FeatureEngineeringClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d310ed4-f3d2-4122-a921-5ff0198bcabe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create \"feature\"/UC table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "679f4cbd-12f6-47bc-b86d-6cee3f7ca89f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_table_name = \"churn_bronze_customers\"\n",
    "churn_feature_table = fe.create_table(\n",
    "  name=f\"{catalog}.{db}.advanced_churn_feature_table\", # f\"{catalog}.{dbName}.{feature_table_name}\"\n",
    "  primary_keys=[\"customer_id\", \"transaction_ts\"],\n",
    "  schema=churn_featuresDF.schema,\n",
    "  timeseries_columns=\"transaction_ts\",\n",
    "  description=f\"These features are derived from the {catalog}.{db}.{bronze_table_name} table in the lakehouse. We created service features and cleaned up their names.  No aggregations were performed. [Warning: This table doesn't store the ground truth and can now be used with AutoML's feature table integration.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81edf906-a755-4f94-a857-448487ddd98b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Write the feature values to a feature table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd21d6d1-e2b9-4c38-bdd4-726abeb0587e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fe.write_table(\n",
    "  name=f\"{catalog}.{db}.advanced_churn_feature_table\",\n",
    "  df=churn_featuresDF, # can be a streaming dataframe as well\n",
    "  mode='merge' #'merge' supports schema evolution\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb86e51d-50e6-48af-ae5d-76d244df2cce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 04. Define Featurization Logic for on-demand feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c083b1e-4a4a-4938-8863-8900b1d418fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION avg_price_increase(\n",
    "  monthly_charges_in DOUBLE, \n",
    "  tenure_in DOUBLE, \n",
    "  total_charges_in DOUBLE\n",
    ")\n",
    "RETURNS FLOAT\n",
    "LANGUAGE PYTHON\n",
    "COMMENT \"[Feature Function] Calculate potential average price increase for tenured customers based on last monthly charges and updated tenure\"\n",
    "AS $$\n",
    "def avg_price_increase(monthly_charges_in, tenure_in, total_charges_in):\n",
    "    if tenure_in > 0:\n",
    "        return monthly_charges_in - total_charges_in / tenure_in\n",
    "    else:\n",
    "        return 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edc60202-0763-4f95-ade8-3182b412961c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE FUNCTION avg_price_increase;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6393772707716444,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02-feature-engineering",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b11b4d50-a2ca-4c8f-887e-1a9fea9e9eec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Use the best AutoML generated notebook to bootstrap our ML Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f70ebf49-ec41-45f4-afed-cfa3b5866b24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 01. LightGBM Classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e7d0414-e33f-43a9-bd5f-4a0f3786fa83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "username = dbutils.notebook.entry_point.getDbutils().notebook().getContext().tags().get(\"user\").get()\n",
    "experiment_name = \"mlops_customer_churn_experiment\"\n",
    "mlflow.set_experiment(f\"/Users/{username}/{experiment_name}\")\n",
    "print(f\"Set experiment to: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5c0e6b5-d95d-4e17-92c6-a3b5c09045d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "671b3cb3-663c-45e2-aced-33d75ad75066",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set the catalog and database to use\n",
    "catalog = \"workspace\"\n",
    "db = \"customer_churn\"\n",
    "spark.sql(f\"USE CATALOG {catalog}\")\n",
    "spark.sql(f\"USE {db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "740c7e9f-215e-454e-b261-cbb260c70073",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(\"advanced_churn_feature_table\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97643b4a-5f7c-45ac-ac63-bf44ca3ae046",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 02. Define feature lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58d72482-7c7c-4841-a1bb-0e2ede65b7b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_store import FeatureFunction, FeatureLookup\n",
    "\n",
    "features = [\n",
    "    FeatureLookup(\n",
    "      table_name=f\"{catalog}.{db}.advanced_churn_feature_table\",\n",
    "      lookup_key=[\"customer_id\"],\n",
    "      timestamp_lookup_key=\"transaction_ts\"\n",
    "    ),\n",
    "    FeatureFunction(\n",
    "      udf_name=f\"{catalog}.{db}.avg_price_increase\",\n",
    "      input_bindings={\n",
    "        \"monthly_charges_in\" : \"monthly_charges\",\n",
    "        \"tenure_in\" : \"tenure\",\n",
    "        \"total_charges_in\" : \"total_charges\"\n",
    "      },\n",
    "      output_name=\"avg_price_increase\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5330530c-b6a9-4708-9583-7674b58b4c89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Pull labels to use for training/validating/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b1c4873-4f49-450d-b3fe-04948d5f6e8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "labels_df = spark.read.table(f\"advanced_churn_label_table\")\n",
    "\n",
    "# Set variable for label column. This will be used within the training code.\n",
    "label_col = \"churn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d1dad6e-43db-40eb-b115-c18da72b0c41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create Training specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "314e1e73-2933-4898-976b-e4f6485e8286",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "# Create Feature specifications object\n",
    "training_set_specs = fe.create_training_set(\n",
    "  df=labels_df, # DataFrame with lookup keys and label/target (+ any other input)\n",
    "  label=\"churn\",\n",
    "  feature_lookups=features,\n",
    "  exclude_columns=[\"customer_id\", \"transaction_ts\", 'split']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b08c451-b182-44dc-b7f9-10d6a6bd5a68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Load training set as Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6134e600-5807-42ca-bbe8-6deaac3a61b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_loaded = training_set_specs.load_df().toPandas()\n",
    "display(df_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bebb1fc-ed99-4e9d-9190-07bad3367c95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 03. Write training code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2cfe8fb-7818-4306-9e88-4f651786e375",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Select supported columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1ceedab-a60f-4709-b1df-914fed3cb228",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.automl_runtime.sklearn.column_selector import ColumnSelector\n",
    "    \n",
    "supported_cols = [\"online_backup\", \"internet_service\", \"payment_method\", \"multiple_lines\", \"paperless_billing\", \"partner\", \"tech_support\", \"tenure\", \"contract\", \"avg_price_increase\", \"phone_service\", \"streaming_movies\", \"dependents\", \"senior_citizen\", \"num_optional_services\", \"device_protection\", \"monthly_charges\", \"total_charges\", \"streaming_tv\", \"gender\", \"online_security\"]\n",
    "\n",
    "col_selector = ColumnSelector(supported_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eda8b444-dc6a-4b12-adcd-3cdddbe3e29c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Preprocessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c15fefe-d5c1-434d-b894-86ebe03ec600",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Boolean columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ffbd8c7-abf4-4835-82be-0caf744f520d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder as SklearnOneHotEncoder\n",
    "\n",
    "\n",
    "bool_imputers = []\n",
    "\n",
    "bool_pipeline = Pipeline(steps=[\n",
    "    (\"cast_type\", FunctionTransformer(lambda df: df.astype(object))),\n",
    "    (\"imputers\", ColumnTransformer(bool_imputers, remainder=\"passthrough\")),\n",
    "    (\"onehot\", SklearnOneHotEncoder(handle_unknown=\"ignore\", drop=\"first\")),\n",
    "])\n",
    "\n",
    "bool_transformers = [(\"boolean\", bool_pipeline, [\"gender\", \"phone_service\", \"dependents\", \"senior_citizen\", \"paperless_billing\", \"partner\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7ccd4ed-e142-416f-a64e-1582ce414653",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7910708c-3e2c-4d0f-8169-57c9bfcc1f31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "num_imputers = []\n",
    "num_imputers.append((\"impute_mean\", SimpleImputer(), [\"avg_price_increase\", \"monthly_charges\", \"num_optional_services\", \"tenure\", \"total_charges\"]))\n",
    "\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    (\"converter\", FunctionTransformer(lambda df: df.apply(pd.to_numeric, errors='coerce'))),\n",
    "    (\"imputers\", ColumnTransformer(num_imputers)),\n",
    "    (\"standardizer\", StandardScaler()),\n",
    "])\n",
    "\n",
    "numerical_transformers = [(\"numerical\", numerical_pipeline, [\"monthly_charges\", \"total_charges\", \"avg_price_increase\", \"tenure\", \"num_optional_services\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fed3e08e-34c9-4fcf-aa61-ff963c579e5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44ed8430-4420-453a-93f5-04cd9f972e80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from databricks.automl_runtime.sklearn import OneHotEncoder\n",
    "\n",
    "\n",
    "one_hot_imputers = []\n",
    "one_hot_pipeline = Pipeline(steps=[\n",
    "    (\"imputers\", ColumnTransformer(one_hot_imputers, remainder=\"passthrough\")),\n",
    "    (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"indicator\")),\n",
    "])\n",
    "\n",
    "categorical_one_hot_transformers = [(\"onehot\", one_hot_pipeline, [\"contract\", \"device_protection\", \"internet_service\", \"multiple_lines\", \"online_backup\", \"online_security\", \"payment_method\", \"streaming_movies\", \"streaming_tv\", \"tech_support\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59d150d7-4a87-4d89-b3cd-f678e0cefc6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "transformers = bool_transformers + numerical_transformers + categorical_one_hot_transformers\n",
    "preprocessor = ColumnTransformer(transformers, remainder=\"passthrough\", sparse_threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b17a20d5-a35d-4f3e-b073-a9d1f95cd21c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 04. Train - Validation - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34f75dbc-3504-4c33-8e7a-ecff90e2de5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(df_loaded.drop(label_col, axis=1), df_loaded[label_col], test_size=0.4, stratify=df_loaded[label_col], random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval, test_size=0.5, stratify=y_eval, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2049361-4d80-45f4-abe9-3de94366e112",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 05. Train classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48e0b252-67e3-43f8-a6a1-519d839e3eb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "help(LGBMClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6aab1ffa-f1cb-496e-a195-057b96f873c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Define the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bd0e0a4-fe82-45ed-81bb-d67803a7687e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import Model, infer_signature, ModelSignature\n",
    "from mlflow.pyfunc import PyFuncModel\n",
    "from mlflow import pyfunc\n",
    "import sklearn\n",
    "from sklearn import set_config\n",
    "from sklearn.pipeline import Pipeline\n",
    "from hyperopt import hp, tpe, fmin, STATUS_OK, Trials\n",
    "\n",
    "\n",
    "\n",
    "# Create a separate pipeline to transform the validation dataset. This is used for early stopping.\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "pipeline_val = Pipeline([\n",
    "    (\"column_selector\", col_selector),\n",
    "    (\"preprocessor\", preprocessor),\n",
    "])\n",
    "pipeline_val.fit(X_train, y_train)\n",
    "X_val_processed = pipeline_val.transform(X_val)\n",
    "\n",
    "def objective(params):\n",
    "  with mlflow.start_run(run_name=\"mlops_best_run\") as mlflow_run: # experiment_id=run['experiment_id']\n",
    "    lgbmc_classifier = LGBMClassifier(**params)\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"column_selector\", col_selector),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", lgbmc_classifier),\n",
    "    ])\n",
    "\n",
    "    # Enable automatic logging of input samples, metrics, parameters, and models\n",
    "    mlflow.sklearn.autolog(\n",
    "        log_input_examples=True,\n",
    "        log_models=False,\n",
    "        silent=True)\n",
    "\n",
    "    model.fit(X_train, y_train, classifier__callbacks=[lightgbm.early_stopping(5), lightgbm.log_evaluation(0)], classifier__eval_set=[(X_val_processed,y_val)])\n",
    "\n",
    "    import warnings\n",
    "    from mlflow.types.utils import _infer_schema\n",
    "    from mlflow.exceptions import MlflowException\n",
    "\n",
    "    # Log the model\n",
    "\n",
    "    # Infer output schema\n",
    "    try:\n",
    "      output_schema = _infer_schema(y_train)\n",
    "    except Exception as e:\n",
    "      warnings.warn(f\"Could not infer model output schema: {e}\")\n",
    "      output_schema = None\n",
    "    \n",
    "    # Use the Feature Engineering client to log the model\n",
    "    # This logs the feature specifications along with the model,\n",
    "    # allowing it to be used at inference time to retrieve features\n",
    "    fe.log_model(\n",
    "        model=model,\n",
    "        artifact_path=\"model\",\n",
    "        flavor=mlflow.sklearn,\n",
    "        training_set=training_set_specs,\n",
    "        output_schema=output_schema,\n",
    "        extra_pip_requirements=[\"databricks-feature-lookup>=1.5.0\"]\n",
    "    )\n",
    "\n",
    "    # Log metrics for the training set\n",
    "    mlflow_model = Model()\n",
    "    pyfunc.add_to_model(mlflow_model, loader_module=\"mlflow.sklearn\")\n",
    "    pyfunc_model = PyFuncModel(model_meta=mlflow_model, model_impl=model)\n",
    "    training_eval_result = mlflow.evaluate(\n",
    "        model=pyfunc_model,\n",
    "        data=X_train.assign(**{str(label_col):y_train}),\n",
    "        targets=label_col,\n",
    "        model_type=\"classifier\",\n",
    "        evaluator_config = {\"log_model_explainability\": False,\n",
    "                            \"metric_prefix\": \"training_\" , \"pos_label\": \"Yes\" }\n",
    "    )\n",
    "    lgbmc_training_metrics = training_eval_result.metrics\n",
    "\n",
    "    # Log metrics for the validation set\n",
    "    val_eval_result = mlflow.evaluate(\n",
    "        model=pyfunc_model,\n",
    "        data=X_val.assign(**{str(label_col):y_val}),\n",
    "        targets=label_col,\n",
    "        model_type=\"classifier\",\n",
    "        evaluator_config = {\"log_model_explainability\": False,\n",
    "                            \"metric_prefix\": \"val_\" , \"pos_label\": \"Yes\" }\n",
    "    )\n",
    "    lgbmc_val_metrics = val_eval_result.metrics\n",
    "\n",
    "    # Log metrics for the test set\n",
    "    test_eval_result = mlflow.evaluate(\n",
    "        model=pyfunc_model,\n",
    "        data=X_test.assign(**{str(label_col):y_test}),\n",
    "        targets=label_col,\n",
    "        model_type=\"classifier\",\n",
    "        evaluator_config = {\"log_model_explainability\": False,\n",
    "                            \"metric_prefix\": \"test_\" , \"pos_label\": \"Yes\" }\n",
    "    )\n",
    "    lgbmc_test_metrics = test_eval_result.metrics\n",
    "\n",
    "    loss = -lgbmc_val_metrics[\"val_f1_score\"]\n",
    "\n",
    "    # Truncate metric key names so they can be displayed together\n",
    "    lgbmc_val_metrics = {k.replace(\"val_\", \"\"): v for k, v in lgbmc_val_metrics.items()}\n",
    "    lgbmc_test_metrics = {k.replace(\"test_\", \"\"): v for k, v in lgbmc_test_metrics.items()}\n",
    "\n",
    "    return {\n",
    "      \"loss\": loss,\n",
    "      \"status\": STATUS_OK,\n",
    "      \"val_metrics\": lgbmc_val_metrics,\n",
    "      \"test_metrics\": lgbmc_test_metrics,\n",
    "      \"model\": model,\n",
    "      \"run\": mlflow_run,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26144251-9b7c-4c7c-9048-b2d7047b1fa1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Configure the hyperparameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf3e987b-b165-407c-97cd-9d1f4d312a41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "  \"colsample_bytree\": 0.4120544919020157,\n",
    "  \"lambda_l1\": 2.6616074270114995,\n",
    "  \"lambda_l2\": 514.9224373768443,\n",
    "  \"learning_rate\": 0.0778497372371143,\n",
    "  \"max_bin\": 229,\n",
    "  \"max_depth\": 9,\n",
    "  \"min_child_samples\": 66,\n",
    "  \"n_estimators\": 250,\n",
    "  \"num_leaves\": 100,\n",
    "  \"path_smooth\": 61.06596877554017,\n",
    "  \"subsample\": 0.6965257092078714,\n",
    "  \"random_state\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8c78b15-2d4e-48dc-8051-7395e8f5d507",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Run trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "960dc18d-be78-41ca-9086-c56dbb77581b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "fmin(objective,\n",
    "     space=space,\n",
    "     algo=tpe.suggest,\n",
    "     max_evals=1,  # Increase this when widening the hyperparameter search space.\n",
    "     trials=trials)\n",
    "\n",
    "best_result = trials.best_trial[\"result\"]\n",
    "model = best_result[\"model\"]\n",
    "mlflow_run = best_result[\"run\"]\n",
    "\n",
    "display(\n",
    "  pd.DataFrame(\n",
    "    [best_result[\"val_metrics\"], best_result[\"test_metrics\"]],\n",
    "    index=[\"validation\", \"test\"]))\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40955707-b5ef-43d4-a38b-d3d63e2de300",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 06. Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1ea2eaf-b66c-41ce-a221-8de62e5c6657",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set this flag to True and re-run the notebook to see the SHAP plots\n",
    "shap_enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "940ada73-1b15-47ae-ae6e-a84845b044ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if shap_enabled:\n",
    "    mlflow.autolog(disable=True)\n",
    "    mlflow.sklearn.autolog(disable=True)\n",
    "    from shap import KernelExplainer, summary_plot\n",
    "    # SHAP cannot explain models using data with nulls.\n",
    "    # To enable SHAP to succeed, both the background data and examples to explain are imputed with the mode (most frequent values).\n",
    "    mode = X_train.mode().iloc[0]\n",
    "\n",
    "    # Sample background data for SHAP Explainer. Increase the sample size to reduce variance.\n",
    "    train_sample = X_train.sample(n=min(100, X_train.shape[0]), random_state=790671489).fillna(mode)\n",
    "\n",
    "    # Sample some rows from the validation set to explain. Increase the sample size for more thorough results.\n",
    "    example = X_val.sample(n=min(100, X_val.shape[0]), random_state=790671489).fillna(mode)\n",
    "\n",
    "    # Use Kernel SHAP to explain feature importance on the sampled rows from the validation set.\n",
    "    predict = lambda x: model.predict_proba(pd.DataFrame(x, columns=X_train.columns))\n",
    "    explainer = KernelExplainer(predict, train_sample, link=\"logit\")\n",
    "    shap_values = explainer.shap_values(example, l1_reg=False, nsamples=100)\n",
    "    summary_plot(shap_values, example, class_names=model.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ebbdd95-46ae-4c3f-8283-b0e2d74ff1f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 07. Confusion matrix, ROC, and Precision-Recall curves for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "263a8f54-8ede-45ef-a246-ae13e35174f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from IPython.display import Image\n",
    "\n",
    "# Create temp directory to download MLflow model artifact\n",
    "eval_temp_dir = os.path.join(os.environ[\"SPARK_LOCAL_DIRS\"], \"tmp\", str(uuid.uuid4())[:8])\n",
    "os.makedirs(eval_temp_dir, exist_ok=True)\n",
    "\n",
    "# Download the artifact\n",
    "eval_path = mlflow.artifacts.download_artifacts(run_id=mlflow_run.info.run_id, dst_path=eval_temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "468b86d5-4887-4b5c-8ce7-1cff3eb62a35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Confusion matrix for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d08a6a61-2f57-4c5d-bafe-4c4cf87d4cb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_confusion_matrix_path = os.path.join(eval_path, \"val_confusion_matrix.png\")\n",
    "display(Image(filename=eval_confusion_matrix_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e0a2e71-b7ca-4464-a084-cf1f2c6a635e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### ROC curve for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "783a6b42-8b3b-4890-8632-96a686072064",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_roc_curve_path = os.path.join(eval_path, \"val_roc_curve_plot.png\")\n",
    "display(Image(filename=eval_roc_curve_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98d3417c-e26a-47c8-8048-a18ac81d13ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Precision-Recall curve for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b75722dd-97e6-4dcb-b172-f4e1477d83f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_pr_curve_path = os.path.join(eval_path, \"val_precision_recall_curve_plot.png\")\n",
    "display(Image(filename=eval_pr_curve_path))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_automl_champion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
